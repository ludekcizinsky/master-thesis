{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9801392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c0bd81e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e0e6941a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "from pathlib import Path\n",
    "\n",
    "from utils.render import render_w_pytorch3d\n",
    "from utils.smpl_deformer.smpl_server import SMPLServer\n",
    "from utils.io import load_frame_map_jsonl_restore\n",
    "from preprocess.helpers.human4d_connector import load_default_camdicts\n",
    "\n",
    "import numpy as np\n",
    "from ipywidgets import interact, IntSlider\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "26b705c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = \"/scratch/izar/cizinsky/thesis/output/modric_vs_ribberi\"\n",
    "frame_path_path = f\"{output_dir}/preprocess/frame_map.jsonl\"\n",
    "scene_root = f\"{output_dir}/preprocess/\"\n",
    "h4d_results = load_frame_map_jsonl_restore(frame_path_path, scene_root=scene_root)\n",
    "\n",
    "phalp_res_path = f\"{output_dir}/phalp_v2/results/demo_images.pkl\"\n",
    "default_cam_dicts = load_default_camdicts(phalp_res_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "484e51b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_server = SMPLServer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "900b975d",
   "metadata": {},
   "outputs": [],
   "source": [
    "smpl_faces = smpl_server.smpl.faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "169e3359",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13776, 3)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smpl_faces.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "61dd92f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 2])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "h4d_results[0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5b297bb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Render (PyTorch3D):   0%|          | 0/87 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Render (PyTorch3D):   3%|▎         | 3/87 [00:00<00:02, 28.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid 0: people=[1, 2]\n",
      "fid 1: people=[1, 2]\n",
      "fid 2: people=[1, 2]\n",
      "fid 3: people=[1, 2]\n",
      "fid 4: people=[1, 2]\n",
      "fid 5: people=[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Render (PyTorch3D):  14%|█▍        | 12/87 [00:00<00:02, 29.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid 6: people=[1, 2]\n",
      "fid 7: people=[1, 2]\n",
      "fid 8: people=[1, 2]\n",
      "fid 9: people=[1, 2]\n",
      "fid 10: people=[1, 2]\n",
      "fid 11: people=[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Render (PyTorch3D):  18%|█▊        | 16/87 [00:00<00:02, 29.78it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid 12: people=[1, 2]\n",
      "fid 13: people=[1, 2]\n",
      "fid 14: people=[1, 2]\n",
      "fid 15: people=[1, 2]\n",
      "fid 16: people=[1, 2]\n",
      "fid 17: people=[1, 2]\n",
      "fid 18: people=[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Render (PyTorch3D):  29%|██▊       | 25/87 [00:00<00:02, 29.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid 19: people=[1, 2]\n",
      "fid 20: people=[1, 2]\n",
      "fid 21: people=[1, 2]\n",
      "fid 22: people=[1, 2]\n",
      "fid 23: people=[1, 2]\n",
      "fid 24: people=[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Render (PyTorch3D):  33%|███▎      | 29/87 [00:00<00:01, 29.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid 25: people=[1, 2]\n",
      "fid 26: people=[1, 2]\n",
      "fid 27: people=[1, 2]\n",
      "fid 28: people=[1, 2]\n",
      "fid 29: people=[1, 2]\n",
      "fid 30: people=[1, 2]\n",
      "fid 31: people=[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Render (PyTorch3D):  41%|████▏     | 36/87 [00:01<00:01, 30.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid 32: people=[1, 2]\n",
      "fid 33: people=[1, 2]\n",
      "fid 34: people=[1, 2]\n",
      "fid 35: people=[2]\n",
      "fid 36: people=[2]\n",
      "fid 37: people=[2]\n",
      "fid 38: people=[2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Render (PyTorch3D):  51%|█████     | 44/87 [00:01<00:01, 32.63it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid 39: people=[2]\n",
      "fid 40: people=[2]\n",
      "fid 41: people=[2]\n",
      "fid 42: people=[2]\n",
      "fid 43: people=[1, 2]\n",
      "fid 44: people=[1, 2]\n",
      "fid 45: people=[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Render (PyTorch3D):  60%|█████▉    | 52/87 [00:01<00:01, 30.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid 46: people=[1, 2]\n",
      "fid 47: people=[1, 2]\n",
      "fid 48: people=[1, 2]\n",
      "fid 49: people=[1, 2]\n",
      "fid 50: people=[1, 2]\n",
      "fid 51: people=[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Render (PyTorch3D):  64%|██████▍   | 56/87 [00:01<00:01, 30.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid 52: people=[1, 2]\n",
      "fid 53: people=[1, 2]\n",
      "fid 54: people=[1, 2]\n",
      "fid 55: people=[1, 2]\n",
      "fid 56: people=[1, 2]\n",
      "fid 57: people=[1, 2]\n",
      "fid 58: people=[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Render (PyTorch3D):  74%|███████▎  | 64/87 [00:02<00:00, 30.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid 59: people=[1, 2]\n",
      "fid 60: people=[1, 2]\n",
      "fid 61: people=[1, 2]\n",
      "fid 62: people=[1, 2]\n",
      "fid 63: people=[1, 2]\n",
      "fid 64: people=[1, 2]\n",
      "fid 65: people=[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Render (PyTorch3D):  83%|████████▎ | 72/87 [00:02<00:00, 29.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid 66: people=[1, 2]\n",
      "fid 67: people=[1, 2]\n",
      "fid 68: people=[1, 2]\n",
      "fid 69: people=[1, 2]\n",
      "fid 70: people=[1, 2]\n",
      "fid 71: people=[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Render (PyTorch3D):  86%|████████▌ | 75/87 [00:02<00:00, 29.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid 72: people=[1, 2]\n",
      "fid 73: people=[1, 2]\n",
      "fid 74: people=[1, 2]\n",
      "fid 75: people=[1, 2]\n",
      "fid 76: people=[1, 2]\n",
      "fid 77: people=[1, 2]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Render (PyTorch3D):  93%|█████████▎| 81/87 [00:02<00:00, 29.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid 78: people=[1, 2]\n",
      "fid 79: people=[1, 2]\n",
      "fid 80: people=[1, 2]\n",
      "fid 81: people=[1, 2, 5]\n",
      "Bin size was too small in the coarse rasterization phase. This caused an overflow, meaning output may be incomplete. To solve, try increasing max_faces_per_bin / max_points_per_bin, decreasing bin_size, or setting bin_size to 0 to use the naive rasterization.Bin size was too small in the coarse rasterization phase. This caused an overflow, meaning output may be incomplete. To solve, try increasing max_faces_per_bin / max_points_per_bin, decreasing bin_size, or setting bin_size to 0 to use the naive rasterization.Bin size was too small in the coarse rasterization phase. This caused an overflow, meaning output may be incomplete. To solve, try increasing max_faces_per_bin / max_points_per_bin, decreasing bin_size, or setting bin_size to 0 to use the naive rasterization.Bin size was too small in the coarse rasterization phase. This caused an overflow, meaning output may be incomplete. To solve, try increasing max_faces_per_bin / max_points_per_bin, decreasing bin_size, or setting bin_size to 0 to use the naive rasterization.fid 82: people=[1, 2, 5]\n",
      "fid 83: people=[1, 2, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Render (PyTorch3D): 100%|██████████| 87/87 [00:02<00:00, 29.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fid 84: people=[1, 2, 5]\n",
      "fid 85: people=[1, 2, 5]\n",
      "fid 86: people=[1, 2, 5]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "out = render_w_pytorch3d(\n",
    "    default_cam_dicts,\n",
    "    h4d_results,\n",
    "    smpl_server,\n",
    "    smpl_faces\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eee9429f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fids = sorted(out.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0614c500",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ac762b5680c74b7d97fdc24efe93238c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=0, description='i', max=86), Output()), _dom_classes=('widget-interact',…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(i=IntSlider(min=0, max=len(fids)-1, step=1, value=0))\n",
    "def show(i=0):\n",
    "    fid = fids[i]\n",
    "    rgb = out[fid]\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.imshow(rgb)\n",
    "    plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42935b96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
