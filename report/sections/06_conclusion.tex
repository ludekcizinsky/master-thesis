%% ----------------------------------------------------------------------------
% CVG SA/MA thesis template
%
% Created 03/08/2024 by Tobias Fischer
%% ----------------------------------------------------------------------------

\chapter{Conclusion}

% ------- Instructions for writing the conclusion section:
% List the conclusions of your work and give evidence for these. Often, the discussion and the conclusion sections are fused. 

This thesis studied monocular (and more generally sparse-view) 4D reconstruction of human-centric dynamic scenes with multiple interacting people. The goal was to build an explicit, renderable scene representation that supports both novel view synthesis and motion analysis, while remaining practical to run compared to optimization-heavy pipelines.

\paragraph{Summary of the approach.}
We proposed a hybrid reconstruction pipeline that uses pretrained estimators to obtain per-frame camera parameters and SMPL-X body parameters, instance masks, and an initial canonical per-person 3D Gaussian Splatting (3DGS) model. Building on this initialization, we refine the reconstruction with a two-stage optimization procedure. We first tune a subset of SMPL-X parameters while keeping the 3DGS fixed. We then synthesize additional training views and optimize the 3DGS parameters while keeping camera and SMPL-X parameters fixed. This design prioritizes stability and runtime over jointly optimizing all components.

\paragraph{What worked.}
Across the evaluated Hi4D scenes, our method achieves novel view synthesis quality that is broadly on par with MultiPly (Table~\ref{tab:nvs_results_hi4d}). These results suggest that an explicit 3DGS representation, together with reliable masks and reasonable human and camera priors, can produce plausible renderings and maintain multi-view consistency even when only monocular input is available. In addition, our training stage runs on the order of tens of minutes per scene in our setup (Table~\ref{tab:training_speed_breakdown}), enabling faster iteration than baselines that require long per-scene optimization.

\paragraph{What did not work (yet).}
We observe a clear gap in pose-related metrics (Table~\ref{tab:pose_results_hi4d}) and, more strongly, in mesh reconstruction metrics on both Hi4D and MMM (Table~\ref{tab:reconstruction_results}). While our pose-tuning stage improves the Human3R initialization, residual pose errors remain and directly bias the posed 3DGS during optimization. In addition, our meshes are extracted via TSDF fusion from per-person depth maps rendered from a rendering-optimized 3DGS representation, which provides only an approximate geometry signal. This makes high-fidelity geometry harder than in methods that directly optimize an implicit surface representation.

\paragraph{Most direct next steps.}
The most promising improvements are to use a stronger pose estimator during preprocessing, for example PromptHMR, and to reduce systematic pose errors with additional pose refinement. A second direction is to improve the DiFix-based view synthesis component by extending it to take multiple reference views and refine multiple target views jointly, and by training the refinement model on human-centric data. These changes aim to preserve the practical runtime of the pipeline while improving pose accuracy and appearance quality.
