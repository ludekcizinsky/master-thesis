%% ----------------------------------------------------------------------------
% CVG SA/MA thesis template
%
% Created 03/08/2024 by Tobias Fischer
%% ----------------------------------------------------------------------------

\chapter{Conclusion}

% ------- Instructions for writing the conclusion section:
% List the conclusions of your work and give evidence for these. Often, the discussion and the conclusion sections are fused. 

This thesis studied monocular (and more generally sparse-view) 4D reconstruction of human-centric dynamic scenes with multiple interacting people. The goal was to build an explicit, renderable scene representation that supports both novel view synthesis and motion analysis, while remaining practical to run compared to optimization-heavy pipelines.

\paragraph{Summary of the approach.}
We proposed a hybrid reconstruction pipeline that uses pretrained estimators to obtain per-frame cameras and SMPL-X body parameters, instance masks, and an initial canonical per-person 3D Gaussian Splatting (3DGS) model. We then optimize only the explicit 3DGS parameters, while keeping cameras and body parameters fixed, and use synthesized additional training views to densify supervision. This design prioritizes stability and runtime over jointly optimizing all components.

\paragraph{What worked.}
Across the evaluated Hi4D scenes, using SAM3 we were able to obtain strong instance segmentation quality (Table~\ref{tab:segmentation_results_hi4d}) and competitive novel view synthesis in terms of SSIM (Table~\ref{tab:nvs_results_hi4d}). These results suggest that an explicit 3DGS representation, together with reliable masks and reasonable human and camera priors, can produce plausible renderings and maintain multi-view consistency even when only monocular input is available. In addition, the pipeline runs end-to-end on the order of minutes per scene in our setup, enabling faster iteration than baselines that require long per-scene optimization.

\paragraph{What did not work (yet).}
We observe a clear gap in pose-related metrics (Table~\ref{tab:pose_results_hi4d}) and, more strongly, in mesh reconstruction metrics on both Hi4D and MMM (Table~\ref{tab:reconstruction_results}). The main limitation is that we keep pose and cameras fixed during training: residual errors directly bias the learned canonical Gaussians and cannot be corrected downstream. A second limitation is representation-related: 3DGS is optimized for view-consistent rendering, and extracting a surface from Gaussians is only an approximation, which makes high-fidelity geometry harder than in methods that directly optimize an implicit surface representation.

\paragraph{Most direct next steps.}
The most promising improvements are to (i) add pose refinement (e.g., 2D keypoint-guided refinement and/or joint optimization of pose during training) to reduce systematic pose errors, (ii) improve 3DGS initialization from LHM robustness (e.g., selecting initialization frames with better visibility and merging multiple candidates), and (iii) use alternative extraction procedures to obtain more reliable meshes from the learned Gaussians. These changes aim to preserve the practical runtime of the pipeline while improving geometric fidelity and appearance quality.
