\PassOptionsToPackage{authoryear,round}{natbib}
\documentclass[11pt]{article}
\usepackage{thesis}

\usepackage{hyperref}       % hyperlinks
\usepackage{url}            % simple URL typesetting
\usepackage{booktabs}       % professional-quality tables
\usepackage{amsfonts}       % blackboard math symbols
\usepackage{nicefrac}       % compact symbols for 1/2, etc.
\usepackage{microtype}      % microtypography
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{titling}
\usepackage{caption}
\captionsetup{labelsep=period}
%\usepackage[font=small]{caption}
\setlength{\droptitle}{-40pt}  % Adjust as needed

\usepackage{titlesec}

\titlespacing{\section}
  {0pt}    % left margin
  {0.7ex plus 0.5ex minus .2ex}  % space before section title
  {0.7ex plus .2ex}  % space after section title (before paragraph)

\titlespacing{\subsection}
  {0pt}
  {1.2ex plus 0.3ex minus .2ex}
  {0.6ex plus .1ex}

\title{\vspace{-1em}{\Large\textbf{Monocular 4D Reconstruction of (in-the-wild) Scenes with Multiple People}}\vspace{-1em}}

\author{
  \begin{tabular}{c c}
  Ludek Cizinsky \\
  \texttt{ludek.cizinsky@epfl.ch} \\
  EPFL
  \end{tabular}
}

\begin{document}

\date{}
\maketitle

\begin{abstract}
% Brief summary of the problem, method, and results (to be written last)
\end{abstract}


\section{Introduction}
% Problem context and motivation
% - I see two important applications of my work
% - First: interactive media - we no longer have to rely on watching monocular feed, and instead can view the given video from any angle we want. This is especially useful in sports broadcasting, where the viewer can choose their own perspective. Here, the important aspect of the reconstruction is how accurate the extracted motion is, and how realistic the novel view renderings are.
% - Second: With the recent advances in humanoid robotics, being able to precisely recover human motion from monocular videos can help extract training motion data for robots to imitate. Here, we only care about the accuracy of the recovered motion, and not so much about the visual quality of the renderings.
% Challenges in monocular dynamic scene reconstruction
% - General challenges in dynamic scene reconstruction
% -- In general, 4D reconstruction from monocular video is highly ill-posed problem
% -- Apart from obtaining multi-view consistency from monocular video, we also have to ensure temporal consistency
% -- In addition, the system needs to be able to accurately disentangle the motion of camera and objects in the scene
% - Specific challenges in human-centric reconstruction
% -- Humans are highly non-rigid objects, with complex articulations and deformations including clothing dynamics and hair motion
% -- Human motion is often fast and unpredictable, leading to motion blur and occlusions
% -- when we have multiple people in the scene, we have to deal with inter-person occlusions and interactions  
% Gap in existing methods
% - Majority of the existing human-centric scenes methods focues on mapping either single image, set of image or monocular video to parametric human model (SMPL, SMPL-X, etc.). These approaches assume clean video capture conditions and fail for the in the wild scenarios where we might have multiple people interacting and occluding each other. 
% - In the last year or two, there has been a new wave of papers that deviate from the tradional 3D reconstruction methods, and instead, train a feedforward network to directly map the input image or video to the target set of modalities, usually depth maps and camera parameters. The main limitation of these approaches is that while at a first glance they give decent predictions, they are still much less acurrate than their more classical optimisation based counterparts. 
% - While there have been previous attempts for monocular 4D reconstruction of dynamic human centric scenes, the main limitation of these approaches is that they require order of hours to days of training time per scene, making them impractical for real world applications. 
% Contributions
% - The main contribution of this work is a novel hybrid framework for monocular 4D reconstruction of dynamic human centric scenes that combines the best of both worlds - the speed and efficiency of feedforward networks, and the accuracy and quality of optimisation based approaches.
% - As a result, we obtain the quality comparable to the state of the art methods that require hours to days of training time, while being able to reconstruct a scene in order of minutes.

% Some notes for relatged work:
% - Free Time GS has shown that under the assumption we have access to a multi-view video of a dynamic scene with complex motions, we can reconstruct high-quality 4D representation of the scene in order of hours to days of training time. However, the main limitation of this approach is that it requires multi-view video capture, which is not always feasible. Therefore, then one might argue is that the problem boilds down to coming up with a video diffusion model that can based on the monocular video input generate novel view videos.
% Examples of state of the art method for lifting monocular video to multi view videos:
% 1. Generative Camera Dolly (GCD) - trained on synthetic data only, if I am not mistaken, can only synthesise one novel video at a time. Also I did test it myself, and the quality of the model is not great.
% 2. Cat4D - this is one of the earliest works. First of all, the model and the data is closed source which signifficantly limits any possible future research since it requites quite signifficant amount of resources to train. If I remember correctly, one of the limitations of this approach is A) it is mostly trained on synthetic data, and B) they show very limited novel view deviation - and this is where it indeed gets very difficult to hallucinate views which are on t he complete other side of the person for instance.
% 3. SV4D - this is I would say open source version of Cat4d. The main problem with this method is that they assume: single object scenes with ideally no background and simple motion. So these are quite limiting constraints.
% --- Also all these methods assume as input input from a **static** camera, which is quite limiting for real world applications.

% Notes on implicit formats:
% - I think that it is important to mention NeRF paper which started this whole wave of implicit neural representations for 3D reconstruction. NeRF back then had two main limitatioshn which was the need for multi view inputs and also really slow training time.
% - This sparked a new direction of papers that addressed these limitations espeically the training time, but still one of the problems with impliciti representation is it is quite hard to compose them where as with 3dgs you can easily train separate gaussians for different objects in the scene and then just combine them together. This also has to do with editability - you can easily move around gaussians in 3d space, whereas with implicit representations this is not so straightforward.
% - Also one of the main issues with NeRF is still its rendering speed - ultimately, i thing in the last two years, we have seen transitiopn from implicit representations to explicit representations and various forms of 3DGS
% - One thing where however implict representations still shines is its generalisation in sparse view settings. By defintin, the implciti model needs to learn a continuous function that maps from 3d space to color and density, so it can interpolate between the known views quite well. On the other hand, explicit representations such as 3dgs need to store all the information in the gaussians themselves, so if there is not enough gaussians to cover the space, it might lead to holes in the reconstruction or just weird artifacts, hence having dense set of views is crucial for good quality reconstruction.

% Notes on dynamic explicit scene representations formats
% - 1. Deformation field over canonical representation: have a canonical space and then then track deformations over time. Of course then the question becomes how to track this motion over time. For instance:
% -- a. use point tracking and then use these points to guide the deformation field 
% -- b. parametric human models (SMPL, SMPL-X, etc.) - however these are limited to humans only
% - 2. Explicit time parametrisation - add time as an additional input to the representation. 
% - 3. Topology chaning representations - e.g. free time gs where gaussians can appear and disappear over time.
% I think the important thing to note here is that choice of different representtion formats then also influences how difficult is to for instance obtain mesh extraction, or how well the representation can handle topology changes.

\section{Related Work}
\subsection{3D Gaussian Splatting}
\subsection{Dynamic Scene Reconstruction}
\subsection{Human-Centric Reconstruction}
\subsection{Novel View Synthesis}
\subsection{Sports and Monocular Reconstruction}

\section{Problem Definition}
% - Input and output specification
% - Assumptions
% - Scope and evaluation goals



\section{Method}
\subsection{Overview}
\subsection{Preprocessing}
\subsection{Camera Setup and Coordinate Systems}
\subsection{Human Representation}
\subsection{Static and Dynamic Gaussian Modeling}
\subsection{Optimization and Training Procedure}
\subsection{Novel View Rendering}
% \subsection{Optional Refinement Stage}

\section{Experimental Setup}
\subsection{Datasets}
\subsection{Baselines}
\subsection{Evaluation Metrics}
\subsection{Implementation Details}

\section{Results}
\subsection{Quantitative Results}
\subsection{Qualitative Results}
\subsection{Ablation Studies}

\section{Discussion}
% - Interpretation of results
% - Strengths and weaknesses
% - Comparison to baselines

\section{Limitations}
% - Failure cases
% - Assumptions that do not hold
% - Scalability and generalization limits

\section{Conclusion}
% - Summary of contributions
% - Key findings
% - Future work

\bibliographystyle{ieee_fullname}
\bibliography{references}

\bibliographystyle{plainnat}
\bibliography{references}

\end{document}